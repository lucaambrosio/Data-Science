{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Istruzioni\n",
    "Valgono le stesse istruzioni delle esercitazioni precedenti. \n",
    "\n",
    "Scrivi il programma Python nella cella sotto il testo dell'esercizio (o creane una nuova). Stampa sempre a video il risultato finale per verificare la correttezza dell'esercizio.  Talvolta richiamiamo alcuni concetti importanti in una cella di codice sotto il testo dell'esercizio, prova a eseguirla ed eventualmente modificarla per assicurarti di aver capito il necessario.\n",
    "\n",
    "**Nota.** Alcuni esercizi potrebbero richiedere una semplice risposta a delle domande. In questo caso potete scrivere la soluzione in una cella di tipo \"Markdown\".  \n",
    "\n",
    "\n",
    "## Consegna\n",
    "Valgono le regole delle esercitazioni precedenti.\n",
    "\n",
    "E' obbligatorio **consegnare la soluzione di tutti gli esercizi** (tranne quelli marcati come opzionali) **entro l'inizio della lezione successiva** (in questo caso entro Lunedi' prossimo), nell'apposito assignment su iCorsi.  Per consegnare:\n",
    "- eseguire l'intero notebook partendo da zero (`Kernel -> Restart & Run All`), e controllare che le soluzioni siano quelle attese;\n",
    "- esportare il notebook in formato html (`File -> Download as...`) e consegnare il file risultante.\n",
    "\n",
    "Nel caso non abbiate potuto completare uno o piu' esercizi, descrivete il problema incontrato e **consegnate comunque il file con il resto delle soluzioni**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 1 \n",
    "\n",
    "Si consideri il dataset visto a lezione e nell'esercitazione precedente sulla classificazione delle cellule tumorali.\n",
    "\n",
    "Quando si lavora con dati provenienti da esami clinici, in genere si dice che un'istanza è di classe positiva (+1) se il test clinico è positivo (es., presenza di tumore maligno), mentre l'istanza è di classe negativa (-1) se il test è negativo (es., il tumore NON è maligno). \n",
    "\n",
    "Il dataset utilizzato non usa questa convenzione. Eseguite la cella sotto per caricare il dataset e convertire la variabile target secondo la convezione descritta sopra (y = 1: tumore maligno; y = -1: tumore benigno). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "ds = sklearn.datasets.load_breast_cancer()\n",
    "\n",
    "x = ds.data\n",
    "yT = ds.target # Il datset originale usa la convezione yT = 0 per tumore maligno, yT = 1 per tumore benigno \n",
    "y = yT\n",
    "\n",
    "# Convertiamo la label secondo la convenzione: y = 1 per tumore maligno, y = -1 per tumore benigno\n",
    "y[yT == 1] = -1\n",
    "y[yT == 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1\n",
    "Dopo aver diviso in **maniera casuale** il dataset completo in set di training (70% delle osservazioni) e set di test (rimanente 30% percento), normalizzate ogni attributo come visto a lezione, in modo che le osservazioni di ogni attributo del training set abbiano media nulla e deviazione standard unitaria. Utilizzando media e deviazione standard **utilizzate per normalizzare gli attributi del training set**, riscalate anche le osservazioni del test set.\n",
    "\n",
    "- Calcolate media e deviazione standard di ogni attributo per le osservazioni del training set. Verificate che siano uguali a 0 e a 1, rispettivamente.\n",
    "\n",
    "- Calcolate media e deviazione standard di ogni attributo per le osservazioni del test set. Sono rispettivamente uguali a 0 e a 1? Perchè? \n",
    "\n",
    "Da ora in avanti, si considerino sempre gli attributi normalizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n",
      "(30,)\n",
      "Trainig set: \n",
      " Media: [1.41855000e+01 1.91928392e+01 9.23355025e+01 6.61859045e+02\n",
      " 9.64749497e-02 1.04080000e-01 8.87943058e-02 4.94785528e-02\n",
      " 1.80698241e-01 6.26464573e-02 4.09096231e-01 1.20445829e+00\n",
      " 2.86661859e+00 4.13843643e+01 6.98354020e-03 2.50993719e-02\n",
      " 3.12257678e-02 1.16784749e-02 2.04023819e-02 3.73508116e-03\n",
      " 1.63596206e+01 2.55345226e+01 1.07736030e+02 8.94246985e+02\n",
      " 1.32529045e-01 2.53368894e-01 2.68530796e-01 1.15221410e-01\n",
      " 2.89186935e-01 8.37181407e-02], \n",
      " Std: [3.59409456e+00 4.18520801e+00 2.47381968e+01 3.66097472e+02\n",
      " 1.38986502e-02 5.09672047e-02 7.80555484e-02 3.91671298e-02\n",
      " 2.80215355e-02 6.85255583e-03 2.93595192e-01 5.51279556e-01\n",
      " 2.10726908e+00 4.97680341e+01 2.85769285e-03 1.68133931e-02\n",
      " 2.85405084e-02 5.85495476e-03 8.17092006e-03 2.63430340e-03\n",
      " 4.95892851e+00 6.13973852e+00 3.44173275e+01 5.97102337e+02\n",
      " 2.29605352e-02 1.53459603e-01 1.93006572e-01 6.56055478e-02\n",
      " 6.33597167e-02 1.79346422e-02]\n",
      "\n",
      "Normalized training set: \n",
      " Media: [-2.26033597e-15 -1.38917353e-16  2.35657390e-15 -6.37680863e-16\n",
      " -1.38219977e-15  1.27393210e-16  1.33129130e-15  5.70035365e-16\n",
      " -3.81436926e-15 -1.68081629e-15 -2.55239715e-16  2.64445082e-16\n",
      " -4.59989389e-16  2.78950509e-17  2.15684533e-15  5.95140910e-16\n",
      "  4.56641983e-16  3.30416878e-16 -1.38917353e-16  1.17466059e-15\n",
      "  1.02346942e-15 -6.34333457e-16 -1.92699011e-15 -1.60675493e-16\n",
      "  3.58311928e-15 -8.60614623e-16 -2.94571737e-16 -6.33217655e-17\n",
      " -5.45069294e-16  3.86883434e-15], \n",
      " Std: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Normalized test set: \n",
      " Media: [ 1.03880517e-15  1.49717795e-15 -1.92178956e-15  1.27253633e-16\n",
      " -9.57648515e-17 -1.26084977e-15 -2.26589378e-16 -6.49253231e-17\n",
      "  1.68805840e-17  2.42788246e-15 -9.85566404e-16 -4.22014600e-16\n",
      "  2.01268502e-17  5.64850311e-16  1.03231264e-15  2.06462527e-16\n",
      " -1.90393510e-16 -1.28105778e-15  6.21984595e-16  3.91824325e-16\n",
      " -8.58312771e-16  1.32983293e-15  2.46716228e-15  6.79118879e-16\n",
      "  2.38925189e-16  8.82984394e-17  2.92813207e-16  2.63596812e-16\n",
      "  1.76337177e-15  1.31473779e-15], \n",
      " Std: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solution (to be completed)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y,test_size = 0.3, random_state = 0)\n",
    "\n",
    "m,n = np.shape(xTrain) # Compute number of observations in training set and maximum number of features\n",
    "\n",
    "# Compute mean and std in training observations\n",
    "xMean = np.mean(xTrain,axis=0)\n",
    "xMean1 = np.mean(xTest,axis=0)\n",
    "print(xMean.shape)\n",
    "xStd = np.std(xTrain,axis=0)\n",
    "xStd1 = np.std(xTest,axis=0)\n",
    "print(xStd.shape)\n",
    "print(f\"Trainig set: \\n Media: {xMean}, \\n Std: {xStd}\\n\")\n",
    "\n",
    "# Scale training data\n",
    "xTrainScaled = (xTrain-xMean)/xStd\n",
    "print(f\"Normalized training set: \\n Media: {np.mean(xTrainScaled, axis = 0)}, \\n Std: {np.std(xTrainScaled, axis = 0)}\\n\")\n",
    "\n",
    "# Scale test data\n",
    "xTestScaled = (xTest-xMean1)/xStd1\n",
    "print(f\"Normalized test set: \\n Media: {np.mean(xTestScaled, axis = 0)}, \\n Std: {np.std(xTestScaled, axis = 0)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2\n",
    "In tutto abbimo 30 attributi. Si considerino i primi due, che corrispondono ai seguenti attributi ['radius_mean', 'texture_mean']. \n",
    "\n",
    "Si generi lo scatterplot per le 2 features con le osservazioni del dataset di training. Disegnate con puntini rossi le osservazioni in cui la variabile target y è uguale a 1 (tumore maligno) e con punti blu le osservazioni in cui la variabile target y è uguale a -1 (tumore benigno).\n",
    "\n",
    "Guardando lo scatterplot appena generato, dite se le seguenti affermazioni sono vere o false\n",
    "- Sia data una variabile di test con 'radius_mean' = 3 e 'texture_mean'= 1. Un algoritmo di classificazione k-NN, con `k=11`, associa la variabile di test alla classe positiva.\n",
    "- Sia data una variabile di test con 'radius_mean' = -1 e 'texture_mean'= 2. Un algoritmo di classificazione k-NN, con `k=11`, associa la variabile di test alla classe positiva.\n",
    "-  Sia data una variabile di test con 'radius_mean' = 1 e 'texture_mean'= -1.1. Un algoritmo di classificazione k-NN, con `k=1`, associa la variabile di test alla classe positiva \n",
    "-  Sia data una variabile di test con 'radius_mean' = 1 e 'texture_mean'= -1.1. Un algoritmo di classificazione k-NN, con `k=5`, associa la variabile di test alla classe positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 1; dimension is 30 but corresponding boolean dimension is 569",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e0cb1460c19a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_notebook_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m data = [go.Scatter(x=xTrainScaled[:,y==1], y=xTrainScaled[:,y==1], \n\u001b[0m\u001b[0;32m      6\u001b[0m             name=\"Tumore maligno\", mode='markers'),\n\u001b[0;32m      7\u001b[0m         go.Scatter(x=xTrainScaled[:,y==-1], y=xTrainScaled[:,y==-1], \n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 1; dimension is 30 but corresponding boolean dimension is 569"
     ]
    }
   ],
   "source": [
    "# Solution (to be completed)\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected = True)\n",
    "data = [go.Scatter(x=xTrainScaled[y==1,0], y=xTrainScaled[y==1,1], \n",
    "            name=\"Tumore maligno\", mode='markers'),\n",
    "        go.Scatter(x=xTrainScaled[y==-1,0], y=xTrainScaled[y==1,1], \n",
    "            name=\"Tumore benigno\", mode='markers')]\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(title=\"f0\"),\n",
    "    yaxis=dict(title=\"f1\",\n",
    "               #scaleanchor = \"x\"\n",
    "              ),\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3\n",
    "### 1.3.1 \n",
    "Scrivere una funzione ``y_hat = knn(xTrainScaled,yTrain,xTestScaled,k,th)`` che implementa l'algoritmo di classificazione k-NN. \n",
    "\n",
    "La funzione riceve come parametri di ingress0:\n",
    "- ``xTrainScaled``: array di 2 dimensioni contente gli attributi (già normalizzati) delle osservazioni del training set. Numero di righe: m (numero di osservazioni), numero di colonne: n (numero degli attributi considerati).\n",
    "- ``yTrain``: array di 1 dimensione contente le m osservazioni della variabile target del training set\n",
    "- ``xTestScaled``: array di 2 dimensioni contente gli attributi (già normalizzati) delle osservazioni del test set di cui si vuole stimare la classe. Numero di righe: t (numero di osservazioni del test set), numero di colonne: n (numero degli attributi considerati).\n",
    "- ``k``: numero intero dispari. Parametro dell'algoritmo k-NN. \n",
    "- ``th``: soglia (o threshould in inglese). Numero intero positivo compreso tra 0 e 1. E' il valore soglia dell'algoritmo. La variabile di test è attributa alla classe positiva se lo ``score`` della classe positiva è maggiore o uguale a ``th``. Data un'istanza di test, lo score della classe positiva  è uguale a $p/k$, dove $p$ è il numero di istanze positive tra le k istanze piu' vicine. Esempio per k=9. Data un'istanza di test, se tra le 9 istanze di training piu' vicine ci sono 5 istanze positive, allora p=5 e lo score è uguale a = 5/9.   Se usate un criterio di maggioranza (come visto a lezione), allora ``th = 0.5``.\n",
    "\n",
    "La funzione restituisce:\n",
    "- ``y_hat``: array di 1 dimensione contente la stima della classe delle t osservazioni del test set\n",
    "- ``y_score``: array di 1 dimensione contente la score (della classe positiva) per ogni osservazione del test set. \n",
    "\n",
    "Valutate il comportamento della funzione appena creata sui dati di test per k=9 e th = 0.5. Usate sempre i primi 2 attributi (radius_mean e texture_mean). Quale è l'accuratezza del vostro classificatore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1.3.1 (to be completed)\n",
    "\n",
    "def knn(xTrainScaled, yTrain, xTestScaled, k, th):\n",
    "    \n",
    "    # Valuta dimensione del set di training\n",
    "    if np.ndim(xTrainScaled)>1:\n",
    "        (m,n) = np.shape(xTrainScaled)\n",
    "    else:\n",
    "        n = 1\n",
    "        m = np.shape(xTrainScaled)[0]\n",
    "        np.reshape(xTrainScaled,(m,1)) # Fai un reshape per avere array di dimension 2\n",
    "        \n",
    "    t = np.shape(xTestScaled)[0] # Dimensione del set di training\n",
    "    \n",
    "    y_hat = np.zeros(t)\n",
    "    y_score = np.zeros(t) \n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return y_hat, y_score\n",
    "\n",
    "\n",
    "y_hat, y_score = knn(xTrainScaled[:,0:2], yTrain, xTestScaled[:,0:2], k=9, th=0.5)\n",
    "accuracy = ...\n",
    "print(f\"Accuratezza: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2  \n",
    "Scrivere una funzione ``accuracy, TP, FP, FN, TN, TPR, FPR = evaluatekNN(yTest,y_hat)`` che, dato l'array con la classe vera ``yTest``delle osservazioni di test e la classe stimata ``y_hat`` dall'algoritmo kNN, restituisce:\n",
    "- accuary: accuratezza dell'algoritmo\n",
    "- TP, FP, FN, TN, TPR, FPR: True Positive, Falso Positive, False Negative, True Negative, True Positive Rate, False Positive Rate.\n",
    "\n",
    "Valutate il comportamento della funzione appena creata usando la predizione della classe y_hat calcolata al passo precedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1.3.2 (to be completed)\n",
    "\n",
    "def evaluatekNN(yTest,y_hat):\n",
    "\n",
    "    ...\n",
    "    \n",
    "    return accuracy, TP, FP, FN, TN, TPR, FPR\n",
    "\n",
    "accuracy, TP, FP, FN, TN, TPR, FPR = evaluatekNN(yTest,y_hat)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}; TPR = {TPR}; FPR = {FPR}; ....... \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 \n",
    "\n",
    "- In un'applicazione diagnostica come quella che stiamo considerando in questo esercizio, è meglio avere un TPR alto (a discapito di un FPR alto) o un TPR basso (col vantaggio di avere un FPR basso)?\n",
    "\n",
    "- Come posso fare ad aumentare (o diminuire) il TPR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4\n",
    "Disegnate la curva ROC (variando il parametro di soglia `th`) per $k=5$, $k=9$ e $k=m$ (dove m è la lunghezza del set di training). Si consideri sempre i primi 2 attributi. \n",
    "\n",
    "- Cosa succede se ``th=0``? E se ``th=1``?\n",
    "\n",
    "- Calcolare la AUC (area under curve) delle 3 ROC disegnate sopra: comando per calcolare la AUC:  ``roc_auc_score(yTest,y_score)``\n",
    "\n",
    "- (opzionale) Sapete spiegare perchè per $k=m$ il classificatore si comporta sempre come il baseline (dummy) classifier?\n",
    "\n",
    "- Quale dei 3 classificatori scegliete? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1.3.4 (to be completed)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "kvec = [5,9,m]\n",
    "data = [] # Qui metterò i dati per disegnare la ROC. Ogni elemento della lista sarà un oggetto di classe go.Scatter  \n",
    "AUC = [] # Area under curve. Sarà una lista con 3 elementi (un elemento per ogni valore di \"k\")\n",
    "\n",
    "for k in kvec: \n",
    "    \n",
    "    thvec = np.linspace(0,1,k+1) #Valori di soglia considerati\n",
    "    TPRlist = [] # In questa lista inseriro' il TPR per ogni valore di soglia. Nota che la lista viene inizializzata ogni volta che cambio \"k\"\n",
    "    FPRlist = [] # In questa lista inseriro' il FPR per ogni valore di soglia.\n",
    "    \n",
    "    \n",
    "    for th in thvec:\n",
    "\n",
    "        y_hat,y_score = ...\n",
    "        \n",
    "        ...\n",
    "    \n",
    "    \n",
    "    AUC.append(roc_auc_score(yTest,y_score))\n",
    "    data.append(go.Scatter(x = FPRlist, y = TPRlist, text = tvec, mode = 'markers+lines', name = f'k-NN classifier for k={k}'))\n",
    "    print(f\"k = {k}: AUC: {AUC[-1]}\")\n",
    "\n",
    "\n",
    "data.append(go.Scatter(x = [0, 1], y = [0, 1], mode = 'lines', name = 'baseline classifier', line = dict(dash = 'dash')))\n",
    "layout = go.Layout(xaxis = dict(title = 'FPR'), yaxis = dict(title = 'TPR'), title = 'Curva ROC del classificatore k-NN sul dataset Breast Cancer')\n",
    "\n",
    "fig = go.Figure(data, layout)\n",
    "py.iplot(fig)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 (simile all'esercizio fatto nell'esercitazione scorsa)\n",
    "Si calcoli l'indice di accuratezza (sul test set) dell'algoritmo di classificazione k-NN (per k=9 e th=0.5) considerando un numero crescente dei possibili attributi. Nello specifico, dati i possibili attributi ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'area_worst', 'smoothness_worst'], si calcoli l'indice di accuratezza per i seguenti casi:\n",
    "- attributi considerati: ['radius_mean', 'texture_mean']\n",
    "- attributi considerati: ['radius_mean', 'texture_mean', 'perimeter_mean']\n",
    "- attributi considerati: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean']\n",
    "- ...\n",
    "- attributi considerati: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'area_worst', 'smoothness_worst']\n",
    "\n",
    "La cella sotto carica tutti i 9 attributi di sopra negli array ``xTrain2`` e ``xTest2``  \n",
    "\n",
    "E' vero che all'aumentare del numero di attributi l'indice di accuratezza aumenta sempre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution (to be completed)\n",
    "\n",
    "index = [0,1,3,4,5,6,7,23,24] # indici degli attributi considerati nei dataset xTrain e xTest\n",
    "xTrain2 = xTrainScaled[:,index]\n",
    "xTest2 = xTestScaled[:,index]\n",
    "\n",
    "k = 9\n",
    "th = 0.5\n",
    "\n",
    "accuracyList = []\n",
    "\n",
    "\n",
    "for n in range(2,10):\n",
    "    print(f\"Numero di attributi considerati = {n}\\n\")\n",
    "    y_hat,y_score = ... \n",
    "    accuracy, TP, FP, FN, TN, TPR, FPR = evaluatekNN(yTest,y_hat)\n",
    "    accuracyList.append(accuracy)\n",
    "\n",
    "print(accuracyList) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 (opzionale, ma vi consigliamo di provare a farlo per capire bene come funziona la cross-validation): Scelta delle features tramite K-fold cross-validation\n",
    "\n",
    "Si implementi un metodo di cross-validation per scegliere la migliore combinazione delle features tra 10 possibili combinazioni. \n",
    "\n",
    "Si consideri sempre un k-nearest-neighbor con $k=5$ e $th=0.5$.\n",
    "\n",
    "Per implementare il metodo di cross-validation, dovete ripartire il dataset di training in $K$ sottoinsiemi disgiunti (ed esaustivi). Usiamo $K=4$.\n",
    "\n",
    "La cella sotto vi mostra un possibile modo di implementare la cross-validation, usando una classe disponibile in sklearn.  Nota: Potete anche fare voi la divisione manualmente, senza usare i comandi di sklearn riportati nella cella sotto. \n",
    "\n",
    "Nota: Ripasso sulla K-fold cross-validation, per K=4. Dopo aver suddiviso il dataset in 4 sottoinsiemi, usate 3 insiemi per fare il training, e il restante per misurare l'accuratezza. Ripete l'operazione 4 volte cambiando ogni volta il set di test e calcolate l'accuratezza come media aritmetica delle accuratezze. Dovete ripete questa operazione per tutte le possibile combinazioni degli attributi e scegliere la combinazione con l'accuratezza media massima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio: divisione di un dataset in K=3 fold\n",
    "\n",
    "# Creo un semplice dataset\n",
    "x_toy = np.random.rand(10,2) # 10 osservazioni e 2 features\n",
    "y_toy = np.array([1, 1, 1, 1, 1, -1, -1, -1, -1, -1])\n",
    "\n",
    "print(\"Dataset completo\\n\", x_toy)\n",
    "print()\n",
    "\n",
    "import sklearn.model_selection\n",
    "K = 3\n",
    "kf = sklearn.model_selection.KFold(n_splits=K, shuffle=True)\n",
    "splits = list(kf.split(x_toy))\n",
    "print(f\"Splits e' una lista di K={len(splits)} tuple\\n\")\n",
    "\n",
    "# ogni tupla e' composta da due elementi:\n",
    "# - il primo e' una lista di indici da usare per il training\n",
    "# - il secondo e' una lista di indici da usare per il testing\n",
    "for train_index, test_index in splits:\n",
    "    print(\"Split:\")\n",
    "    print(\"Indici di training: \", train_index)\n",
    "    print(\"Indici di testing: \", test_index)\n",
    "    x_toy_train = x_toy[train_index, :]\n",
    "    y_toy_train = y_toy[train_index]\n",
    "    x_toy_test  = x_toy[test_index , :]\n",
    "    y_toy_test  = y_toy[test_index]\n",
    "    print(\"Dati di training:\\n\", x_toy_train)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 Implementazione della cross validation\n",
    "\n",
    "Per una determinata scelta delle feature (ad esempio, quelle agli indici `[0,1,3,4,5,6,7,23,24]`), calcola l'accuratezza del classificatore mediante 4-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1.5.1 (to be completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 Comparazione tra diversi sottoinsiemi di feature\n",
    "\n",
    "Scopri quali tra le combinazioni di feature proposte sotto e' preferibile, calcolando per ciascuna delle 6 combinazioni l'accuratezza tramite K-fold cross validation.\n",
    "\n",
    "Esempio di output:\n",
    "```\n",
    "Considero le features: [0]\n",
    "Accuracy per un fold: 0.8181818181818182\n",
    "Accuracy per un fold: 0.8661971830985915\n",
    "Accuracy per un fold: 0.9225352112676056\n",
    "Accuracy per un fold: 0.8591549295774648\n",
    "Accuracy media: 0.8665172855313701\n",
    "\n",
    "Considero le features: [0, 1]\n",
    "Accuracy per un fold: 0.8531468531468531\n",
    "Accuracy per un fold: 0.8591549295774648\n",
    "Accuracy per un fold: 0.9154929577464789\n",
    "Accuracy per un fold: 0.8802816901408451\n",
    "Accuracy media: 0.8770191076529105\n",
    "\n",
    "Considero le features: [0, 1, 3]\n",
    "Accuracy per un fold: 0.8671328671328671\n",
    "Accuracy per un fold: 0.8591549295774648\n",
    "Accuracy per un fold: 0.9084507042253521\n",
    "Accuracy per un fold: 0.8802816901408451\n",
    "Accuracy media: 0.8787550477691323\n",
    "\n",
    "Considero le features: [0, 1, 3, 4, 5, 6, 7, 23, 24]\n",
    "Accuracy per un fold: 0.9300699300699301\n",
    "Accuracy per un fold: 0.971830985915493\n",
    "Accuracy per un fold: 0.971830985915493\n",
    "Accuracy per un fold: 0.9507042253521126\n",
    "Accuracy media: 0.9561090318132571\n",
    "\n",
    "Considero le features: [3, 4]\n",
    "Accuracy per un fold: 0.8671328671328671\n",
    "Accuracy per un fold: 0.8873239436619719\n",
    "Accuracy per un fold: 0.9084507042253521\n",
    "Accuracy per un fold: 0.8732394366197183\n",
    "Accuracy media: 0.8840367379099774\n",
    "\n",
    "Considero le features: [7, 23, 24]\n",
    "Accuracy per un fold: 0.9230769230769231\n",
    "Accuracy per un fold: 0.971830985915493\n",
    "Accuracy per un fold: 0.9436619718309859\n",
    "Accuracy per un fold: 0.9366197183098591\n",
    "Accuracy media: 0.9437973997833152\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1.5.2 (to be completed)\n",
    "\n",
    "featurecombinations = [[0                  ],\n",
    "                       [0,1                ],\n",
    "                       [0,1,3              ],\n",
    "                       [0,1,3,4,5,6,7,23,24],\n",
    "                       [    3,4            ],\n",
    "                       [            7,23,24]]\n",
    "\n",
    "K = 4 # numero di fold\n",
    "kf = sklearn.model_selection.KFold(n_splits=K, shuffle=True)\n",
    "splits = list(kf.split(x))\n",
    "\n",
    "\n",
    "k = 5 # per il knn\n",
    "th = 0.5\n",
    "\n",
    "accuracyPerFeature = [] # Ogni elemento della lista sarà l'accuratezza (media) che si ottiene per una data combinazione di features\n",
    "\n",
    "for featurecombination in featurecombinations: # Ciclo su tutte le combinazioni di features\n",
    "    x_feat = x[:, featurecombination]\n",
    "    \n",
    "    print(f\"Considero le features: {featurecombination}\")\n",
    "    \n",
    "    ### Completare..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3 Comparazione tra tutti i possibili sottoinsiemi di feature\n",
    "\n",
    "Considera tutti i possibili sottoinsiemi delle feature agli indici `[0,1,3,4,5,6,7,23,24]`.  Calcola per ciascun sottoinsieme (ce ne sono in tutto $2^9 - 1$) l'accuratezza mediante 4-fold cross-validation, e trova quello che restituisce accuratezza massima.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1.5.3 (to be completed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
